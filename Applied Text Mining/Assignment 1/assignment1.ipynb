{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cacf7f4360d6d53c622742f64048f72c",
     "grade": false,
     "grade_id": "cell-8a754c8ce8a16eeb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 1\n",
    "\n",
    "In this assignment, you'll be working with messy medical data and using regex to extract relevant infromation from the data. \n",
    "\n",
    "Each line of the `dates.txt` file corresponds to a medical note. Each note has a date that needs to be extracted, but each date is encoded in one of many formats.\n",
    "\n",
    "The goal of this assignment is to correctly identify all of the different date variants encoded in this dataset and to properly normalize and sort the dates. \n",
    "\n",
    "Here is a list of some of the variants you might encounter in this dataset:\n",
    "* 04/20/2009; 04/20/09; 4/20/09; 4/3/09\n",
    "* Mar-20-2009; Mar 20, 2009; March 20, 2009;  Mar. 20, 2009; Mar 20 2009;\n",
    "* 20 Mar 2009; 20 March 2009; 20 Mar. 2009; 20 March, 2009\n",
    "* Mar 20th, 2009; Mar 21st, 2009; Mar 22nd, 2009\n",
    "* Feb 2009; Sep 2009; Oct 2010\n",
    "* 6/2008; 12/2009\n",
    "* 2009; 2010\n",
    "\n",
    "Once you have extracted these date patterns from the text, the next step is to sort them in ascending chronological order accoring to the following rules:\n",
    "* Assume all dates in xx/xx/xx format are mm/dd/yy\n",
    "* Assume all dates where year is encoded in only two digits are years from the 1900's (e.g. 1/5/89 is January 5th, 1989)\n",
    "* If the day is missing (e.g. 9/2009), assume it is the first day of the month (e.g. September 1, 2009).\n",
    "* If the month is missing (e.g. 2010), assume it is the first of January of that year (e.g. January 1, 2010).\n",
    "* Watch out for potential typos as this is a raw, real-life derived dataset.\n",
    "\n",
    "With these rules in mind, find the correct date in each note and return a pandas Series in chronological order of the original Series' indices. **This Series should be sorted by a tie-break sort in the format of (\"extracted date\", \"original row number\").**\n",
    "\n",
    "For example if the original series was this:\n",
    "\n",
    "    0    1999\n",
    "    1    2010\n",
    "    2    1978\n",
    "    3    2015\n",
    "    4    1985\n",
    "\n",
    "Your function should return this:\n",
    "\n",
    "    0    2\n",
    "    1    4\n",
    "    2    0\n",
    "    3    1\n",
    "    4    3\n",
    "\n",
    "Your score will be calculated using [Kendall's tau](https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient), a correlation measure for ordinal data.\n",
    "\n",
    "*This function should return a Series of length 500 and dtype int.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4b47ce38a503bfb1f113580f394d8667",
     "grade": false,
     "grade_id": "cell-28048f36edc32946",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         03/25/93 Total time of visit (in minutes):\\n\n",
       "1                       6/18/85 Primary Care Doctor:\\n\n",
       "2    sshe plans to move as of 7/8/71 In-Home Servic...\n",
       "3                7 on 9/27/75 Audit C Score Current:\\n\n",
       "4    2/6/96 sleep studyPain Treatment Pain Level (N...\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "doc = []\n",
    "\n",
    "\n",
    "with open(\"assets/dates.txt\") as file:\n",
    "    for line in file:\n",
    "        doc.append(line)\n",
    "\n",
    "df = pd.Series(doc)\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_sorter():\n",
    "    text = df.copy()\n",
    "    text = text.str.lower()\n",
    "    months = \"(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\"\n",
    "    extracted_dates = text.str.extract(\n",
    "        r\"(?P<month>\\d?\\d)[/-](?P<day>\\d?\\d)[/-](?P<year>\\d{4})\"\n",
    "    )\n",
    "\n",
    "    not_extracted = ~text.index.isin(extracted_dates.dropna().index)\n",
    "    extracted_dates = pd.concat(\n",
    "        [\n",
    "            extracted_dates,\n",
    "            text[not_extracted].str.extract(\n",
    "                r\"(?P<month>\\d?\\d)[/-](?P<day>(?:[0-2]?[0-9])|(?:[3][01]))[/-](?P<year>\\d{2})\"\n",
    "            ),\n",
    "        ],\n",
    "        axis=0,\n",
    "        join=\"inner\",\n",
    "    )\n",
    "    not_extracted = ~text.index.isin(extracted_dates.dropna().index)\n",
    "\n",
    "    extracted_dates = pd.concat(\n",
    "        [\n",
    "            extracted_dates,\n",
    "            text[not_extracted].str.extract(\n",
    "                r\"(?P<day>\\d?\\d)\\s?(?P<month>(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\\w*)\\.?,?\\s?(?P<year>\\d{4})\"\n",
    "            ),\n",
    "        ],\n",
    "        axis=0,\n",
    "        join=\"inner\",\n",
    "    )\n",
    "    not_extracted = ~text.index.isin(extracted_dates.dropna().index)\n",
    "\n",
    "    extracted_dates = pd.concat(\n",
    "        [\n",
    "            extracted_dates,\n",
    "            text[not_extracted].str.extract(\n",
    "                r\"(?P<month>(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\\w*)\\.?-?\\s?(?P<day>\\d\\d?)(?:th|nd|st)?,?-?\\s?(?P<year>\\d{4})\"\n",
    "            ),\n",
    "        ],\n",
    "        axis=0,\n",
    "        join=\"inner\",\n",
    "    )\n",
    "    not_extracted = ~text.index.isin(extracted_dates.dropna().index)\n",
    "\n",
    "    without_day = text[not_extracted].str.extract(\n",
    "        r\"(?P<month>(?:jan|feb|mar|apr|may|jun|jul|aug|sep|oct|nov|dec)\\w*),?\\.?\\s(?P<year>\\d{4})\"\n",
    "    )\n",
    "    without_day = pd.concat(\n",
    "        [\n",
    "            without_day,\n",
    "            text[not_extracted].str.extract(r\"(?P<month>\\d\\d?)/(?P<year>\\d{4})\"),\n",
    "        ]\n",
    "    )\n",
    "    without_day[\"day\"] = 1\n",
    "    extracted_dates = pd.concat([extracted_dates, without_day])\n",
    "    not_extracted = ~text.index.isin(extracted_dates.dropna().index)\n",
    "\n",
    "    without_month = text[not_extracted].str.extract(r\"(?P<year>\\d{4})\")\n",
    "    without_month[\"day\"] = 1\n",
    "    without_month[\"month\"] = 1\n",
    "    extracted_dates = pd.concat([extracted_dates, without_month])\n",
    "    not_extracted = ~text.index.isin(extracted_dates.dropna().index)\n",
    "    extracted_dates = extracted_dates.dropna()\n",
    "\n",
    "    # Year\n",
    "    extracted_dates[\"year\"] = extracted_dates[\"year\"].apply(\n",
    "        lambda x: \"19\" + x if len(x) == 2 else x\n",
    "    )\n",
    "    extracted_dates[\"year\"] = extracted_dates[\"year\"].apply(lambda x: str(x))\n",
    "\n",
    "    # Month\n",
    "    extracted_dates[\"month\"] = extracted_dates[\"month\"].apply(\n",
    "        lambda x: x[1:] if type(x) is str and x.startswith(\"0\") else x\n",
    "    )\n",
    "    month_dict = {\n",
    "        \"january\": 1,\n",
    "        \"jan\": 1,\n",
    "        \"february\": 2,\n",
    "        \"feb\": 2,\n",
    "        \"march\": 3,\n",
    "        \"mar\": 3,\n",
    "        \"april\": 4,\n",
    "        \"apr\": 4,\n",
    "        \"may\": 5,\n",
    "        \"june\": 6,\n",
    "        \"jun\": 6,\n",
    "        \"july\": 7,\n",
    "        \"jul\": 7,\n",
    "        \"august\": 8,\n",
    "        \"aug\": 8,\n",
    "        \"september\": 9,\n",
    "        \"sep\": 9,\n",
    "        \"october\": 10,\n",
    "        \"oct\": 10,\n",
    "        \"november\": 11,\n",
    "        \"nov\": 11,\n",
    "        \"december\": 12,\n",
    "        \"dec\": 12,\n",
    "        \"age\": 1,\n",
    "        \"janaury\": 1,\n",
    "        \"decemeber\": 12,\n",
    "    }\n",
    "\n",
    "    extracted_dates = extracted_dates.replace(month_dict)\n",
    "    extracted_dates[\"month\"] = extracted_dates[\"month\"].apply(lambda x: str(x))\n",
    "    extracted_dates[\"day\"] = extracted_dates[\"day\"].apply(lambda x: str(x))\n",
    "\n",
    "    extracted_dates[\"day\"] = extracted_dates[\"day\"].apply(\n",
    "        lambda x: pd.NaT if int(x) < 1 or int(x) > 31 else x\n",
    "    )\n",
    "    extracted_dates[\"month\"] = extracted_dates[\"month\"].apply(\n",
    "        lambda x: pd.NaT if int(x) < 1 or int(x) > 12 else x\n",
    "    )\n",
    "    extracted_dates[\"year\"] = extracted_dates[\"year\"].apply(\n",
    "        lambda x: pd.NaT if int(x) < 1900 or int(x) > 2050 else x\n",
    "    )\n",
    "\n",
    "    extracted_dates[\"date\"] = (\n",
    "        extracted_dates[\"month\"]\n",
    "        + \"/\"\n",
    "        + extracted_dates[\"day\"]\n",
    "        + \"/\"\n",
    "        + extracted_dates[\"year\"]\n",
    "    )\n",
    "\n",
    "    extracted_dates[\"date\"] = pd.to_datetime(extracted_dates[\"date\"])\n",
    "    extracted_dates[\"index\"] = extracted_dates.index\n",
    "\n",
    "    extracted_dates = extracted_dates.sort_values(by=[\"date\", \"index\"])\n",
    "    return_rank = pd.Series(list(extracted_dates.index))\n",
    "\n",
    "    return return_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        9\n",
       "1       84\n",
       "2        2\n",
       "3       53\n",
       "4       28\n",
       "      ... \n",
       "495    427\n",
       "496    141\n",
       "497    186\n",
       "498    161\n",
       "499    413\n",
       "Length: 500, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_sorter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed df modification check\n",
      "Passed repeatability check\n",
      "Passed index check\n",
      "Passed secondary sort sample check\n",
      "Values checksums:\n",
      "     correct  learner  agree\n",
      "0       6695     6695   True\n",
      "10     14428    14428   True\n",
      "20     16742    16742   True\n",
      "30      9275     9275   True\n",
      "40     12290    12290   True\n",
      "50     14654    14654   True\n",
      "60      9421     9421   True\n",
      "70     10185    10185   True\n",
      "80     11464    11464   True\n",
      "90     16491    16491   True\n",
      "100    11797    11797   True\n",
      "110    14036    14036   True\n",
      "120    15459    15459   True\n",
      "130     9412     9412   True\n",
      "140    13069    13069   True\n",
      "150    10400    10400   True\n",
      "160    10498    10498   True\n",
      "170    14322    14322   True\n",
      "180    13274    13274   True\n",
      "190    11001    11001   True\n",
      "200    11383    11383   True\n",
      "210    11910    11910   True\n",
      "220    10977    10977   True\n",
      "230     9692     9692   True\n",
      "240    10199    10199   True\n",
      "250    10187    10187   True\n",
      "260    15456    15456   True\n",
      "270    13491    13491   True\n",
      "280     9186     9186   True\n",
      "290    13646    13646   True\n",
      "300    11142    11142   True\n",
      "310    13724    13724   True\n",
      "320    10994    10994   True\n",
      "330    12905    12905   True\n",
      "340    15968    15968   True\n",
      "350    16648    16648   True\n",
      "360    13966    13966   True\n",
      "370    14607    14607   True\n",
      "380    16932    16932   True\n",
      "390    14622    14622   True\n",
      "400    17942    17942   True\n",
      "410    18220    18220   True\n",
      "420    17818    17818   True\n",
      "430    18305    18305   True\n",
      "440    19633    19633   True\n",
      "450    12522    12522   True\n",
      "460    13978    13978   True\n",
      "470    18445    18445   True\n",
      "480    20156    20156   True\n",
      "490    14797    14797   True\n",
      "Passed values check\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "s_test = date_sorter()\n",
    "\n",
    "\n",
    "def run_df_modified_check():\n",
    "    \"\"\"\n",
    "    Check if df appears to be modified.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert type(df) == pd.Series\n",
    "        assert (df.index == pd.RangeIndex(start=0, stop=500, step=1)).all()\n",
    "        assert (df.apply(type) == str).all()\n",
    "        assert df.str.len().min() >= 6\n",
    "        assert df.str[5].apply(ord).sum() == 38354\n",
    "        print(\"Passed df modification check\")\n",
    "    except:\n",
    "        print(\"Failed df modification check\")\n",
    "\n",
    "\n",
    "run_df_modified_check()\n",
    "\n",
    "# check if running the code twice produces the same result\n",
    "try:\n",
    "    assert (date_sorter() == s_test).all()\n",
    "    print(\"Passed repeatability check\")\n",
    "except:\n",
    "    print(\"Failed repeatability check\")\n",
    "\n",
    "# check if the result has the expected index\n",
    "try:\n",
    "    # assert type(date_sorter().index) == pd.RangeIndex\n",
    "    # assert (date_sorter().index == pd.RangeIndex(start=0, stop=500, step=1)).all()\n",
    "    assert list(date_sorter().index) == list(range(500))\n",
    "    print(\"Passed index check\")\n",
    "except:\n",
    "    print(\"Failed index check\")\n",
    "\n",
    "# check the tie-break sort for a sample of records where some have the same date\n",
    "# note that this only tests a sample and does not check the entire answer\n",
    "try:\n",
    "    test_indices = [\n",
    "        335,\n",
    "        415,\n",
    "        323,\n",
    "        405,\n",
    "        370,\n",
    "        382,\n",
    "        303,\n",
    "        488,\n",
    "        283,\n",
    "        395,\n",
    "        318,\n",
    "        369,\n",
    "        493,\n",
    "        252,\n",
    "        314,\n",
    "        410,\n",
    "        490,\n",
    "    ]\n",
    "    answer_lkp = {\n",
    "        original_index: answer_index\n",
    "        for answer_index, original_index in s_test.to_dict().items()\n",
    "    }\n",
    "    i_test = [answer_lkp[i] for i in test_indices]\n",
    "    assert sorted(i_test) == i_test\n",
    "    print(\"Passed secondary sort sample check\")\n",
    "except:\n",
    "    print(\"Failed secondary sort sample check\")\n",
    "\n",
    "\n",
    "def run_v_check(s_test):\n",
    "    \"\"\"\n",
    "    Check if the parsed dates appear to be correct and correctly sorted.\n",
    "    The check works by producing some test checksums\n",
    "    if you get for example a False entry in the agree column for\n",
    "    index value 20 that would mean you have at least one incorrectly\n",
    "    parsed or incorrectly sorted date in the **output** index\n",
    "    range 20,21,...,29\n",
    "    The results of the test are printed.\n",
    "    Args:\n",
    "    s_test: Series such as produced by date_sorter()\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        v_check = pd.DataFrame(\n",
    "            {\n",
    "                \"correct\": [\n",
    "                    6695,\n",
    "                    14428,\n",
    "                    16742,\n",
    "                    9275,\n",
    "                    12290,\n",
    "                    14654,\n",
    "                    9421,\n",
    "                    10185,\n",
    "                    11464,\n",
    "                    16491,\n",
    "                    11797,\n",
    "                    14036,\n",
    "                    15459,\n",
    "                    9412,\n",
    "                    13069,\n",
    "                    10400,\n",
    "                    10498,\n",
    "                    14322,\n",
    "                    13274,\n",
    "                    11001,\n",
    "                    11383,\n",
    "                    11910,\n",
    "                    10977,\n",
    "                    9692,\n",
    "                    10199,\n",
    "                    10187,\n",
    "                    15456,\n",
    "                    13491,\n",
    "                    9186,\n",
    "                    13646,\n",
    "                    11142,\n",
    "                    13724,\n",
    "                    10994,\n",
    "                    12905,\n",
    "                    15968,\n",
    "                    16648,\n",
    "                    13966,\n",
    "                    14607,\n",
    "                    16932,\n",
    "                    14622,\n",
    "                    17942,\n",
    "                    18220,\n",
    "                    17818,\n",
    "                    18305,\n",
    "                    19633,\n",
    "                    12522,\n",
    "                    13978,\n",
    "                    18445,\n",
    "                    20156,\n",
    "                    14797,\n",
    "                ],\n",
    "                \"learner\": [\n",
    "                    (\n",
    "                        s_test.iloc[10 * i : (i + 1) * 10].values\n",
    "                        * np.array(range(1, 11))\n",
    "                    ).sum()\n",
    "                    for i in range(50)\n",
    "                ],\n",
    "            },\n",
    "            index=range(0, 500, 10),\n",
    "        ).assign(agree=lambda x: x[\"correct\"] == x[\"learner\"])\n",
    "        print(\"Values checksums:\")\n",
    "        print(v_check)\n",
    "        assert v_check[\"agree\"].all()\n",
    "        print(\"Passed values check\")\n",
    "    except:\n",
    "        print(\"Failed values check\")\n",
    "    return\n",
    "\n",
    "\n",
    "run_v_check(s_test)"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-text-mining",
   "graded_item_id": "LvcWI",
   "launcher_item_id": "krne9",
   "part_id": "Mkp1I"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
