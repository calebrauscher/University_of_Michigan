{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e45d05a7e6705e7bc18fff5d5890ef58",
     "grade": false,
     "grade_id": "cell-44ca835c70f3040a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false; // disable scroll bar when displaying Folium map\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false; // disable scroll bar when displaying Folium map\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae6111747a75bdb5c5393f44d1045577",
     "grade": false,
     "grade_id": "cell-c676d66924c74eea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "Before working on this assignment please read these instructions fully. In the submission area, you will notice that you can click the link to **Preview the Grading** for each step of the assignment. This is the criteria that will be used for peer grading. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "The data for this assignment comes from a subset of The National Centers for Environmental Information (NCEI) [Global Historical Climatology Network daily (GHCNd)](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily) (GHCN-Daily). The GHCN-Daily is comprised of daily climate records from thousands of land surface stations across the globe - it's a wonderfully large dataset to play with! In particular, you will be asked to use data from the Ann Arbor Michigan location (my home!). and this is stored in the file: `assets/fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89.csv`\n",
    "\n",
    "Each row in this datafile corresponds to a single observation from a weather station, and has the following variables:\n",
    "* **id** : station identification code\n",
    "* **date** : date in YYYY-MM-DD format (e.g. 2012-01-24 = January 24, 2012)\n",
    "* **element** : indicator of element type\n",
    "    * TMAX : Maximum temperature (tenths of degrees C)\n",
    "    * TMIN : Minimum temperature (tenths of degrees C)\n",
    "* **value** : data value for element (tenths of degrees C)\n",
    "\n",
    "For this assignment, you must:\n",
    "\n",
    "1. Read the documentation and familiarize yourself with the dataset, then write a python notebook which plots line graphs of the record high and record low temperatures by day of the year over the period 2005-2014. The area between the record high and record low temperatures for each day should be shaded.\n",
    "2. Overlay a scatter of the 2015 data for any points (highs and lows) for which the ten year record (2005-2014) record high or record low was broken in 2015. (Based on the graph, do you think extreme weather is getting more frequent in 2015?)\n",
    "3. Watch out for leap days (i.e. February 29th), it is reasonable to remove these points from the dataset for the purpose of this visualization.\n",
    "4. Make the visual nice! Leverage principles from the first module in this course when developing your solution. Consider issues such as legends, labels, and chart junk.\n",
    "\n",
    "I've written some steps I think would be good to go through, but there are other ways to solve this assignment so feel free to explore the pandas library! What I really want to see is an image that looks like this sketch I drew at my desk:\n",
    "\n",
    "![](assets/chris_sketch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8d9355fc55599cd2ad34fdd140baac1",
     "grade": false,
     "grade_id": "cell-f01cb0e8645e7c07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_dfdb0c86f78a6a6f35cd2ff771846545 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 500.0px;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_dfdb0c86f78a6a6f35cd2ff771846545&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_dfdb0c86f78a6a6f35cd2ff771846545 = L.map(\n",
       "                &quot;map_dfdb0c86f78a6a6f35cd2ff771846545&quot;,\n",
       "                {\n",
       "                    center: [41.9164, -84.0158],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 9,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_c7cd92a4bdf099dcb8b332364f6c8815 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_c7cd92a4bdf099dcb8b332364f6c8815.addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_10799b92ff5781a35d5075537731afa7 = L.marker(\n",
       "                [41.9164, -84.0158],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_8b6440fd065252fe7efba4adeffea508 = L.marker(\n",
       "                [42.2875, -83.7611],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_ab80ceab1ba371a3f40bb74fff0076df = L.marker(\n",
       "                [42.2417, -83.6933],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_c6511a71a19bfc14bc411aa6d8d07e89 = L.marker(\n",
       "                [42.2947, -83.7108],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_4ac8f083cd136d69d628446d6e7df8d4 = L.marker(\n",
       "                [41.84, -83.8608],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_b6a77599d0993de26d7c8b68d2fa9fbd = L.marker(\n",
       "                [42.0636, -83.4358],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_ea5986cfbd3570a855eb03f9e7c39953 = L.marker(\n",
       "                [42.3264, -84.0133],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_91a565a1ff269114c5e826440cc78bdb = L.marker(\n",
       "                [41.9553, -83.6489],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_1c55d20f26474f179fc5c9873f567826 = L.marker(\n",
       "                [42.4344, -83.9858],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_ca447b52de1f19b45059531f0402729d = L.marker(\n",
       "                [42.1508, -84.0236],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_bf0d5b2c93851859a86813d2675c08d0 = L.marker(\n",
       "                [42.0664, -83.6186],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_d80c1fdc32a6c00f57762619ccfb2607 = L.marker(\n",
       "                [42.0811, -83.6769],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_080b807291c49abcef009dd357561fae = L.marker(\n",
       "                [41.9069, -83.4158],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_d066776c0f2cd1ba07986e211e5b53c9 = L.marker(\n",
       "                [41.9497, -83.28],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_30ece6817e30befe87fffc924393700e = L.marker(\n",
       "                [42.1611, -83.7819],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_8138612a81e4a6090c259524b3424711 = L.marker(\n",
       "                [42.1236, -83.82],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_fb568fbb94ab0c7d97db39d568f94fb1 = L.marker(\n",
       "                [41.8069, -83.5831],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_3369df50052b43dcd3deaf8ced2780b4 = L.marker(\n",
       "                [42.0028, -83.9336],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_9c22f73216f7637544a68c98d3be558f = L.marker(\n",
       "                [42.0283, -84.1108],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_5fd334dd5d461da2fbefa877e84bae81 = L.marker(\n",
       "                [42.4356, -83.7831],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_18752d9b36033aa67fc0b7648e70ce66 = L.marker(\n",
       "                [41.5631, -83.4764],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_a55eef6ef4aa9cd3e2b1a6dbf39c227c = L.marker(\n",
       "                [42.2667, -84.4667],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_d8afd3bd9f4e7cc8e4deffdd13975970 = L.marker(\n",
       "                [42.2333, -83.5333],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "    \n",
       "            var marker_7aa0717b97b1ee88eb8097d47142d6f2 = L.marker(\n",
       "                [42.2228, -83.7444],\n",
       "                {}\n",
       "            ).addTo(map_dfdb0c86f78a6a6f35cd2ff771846545);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x208c243dea0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  I'll be using the folium package to render the data into a map in Jupyter.\n",
    "\n",
    "import folium\n",
    "import pandas as pd\n",
    "\n",
    "# get the location information for this dataset\n",
    "df = pd.read_csv(\"data/BinSize_d400.csv\")\n",
    "station_locations_by_hash = df[\n",
    "    df[\"hash\"] == \"fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89\"\n",
    "]\n",
    "\n",
    "# get longitude and lattitude to plot\n",
    "lons = station_locations_by_hash[\"LONGITUDE\"].tolist()\n",
    "lats = station_locations_by_hash[\"LATITUDE\"].tolist()\n",
    "\n",
    "# plot on a beautiful folium map\n",
    "my_map = folium.Map(location=[lats[0], lons[0]], height=500, zoom_start=9)\n",
    "for lat, lon in zip(lats, lons):\n",
    "    folium.Marker([lat, lon]).add_to(my_map)\n",
    "\n",
    "# render map in Jupyter\n",
    "display(my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2ee9d3c5ac53844b3ed48aa157f6204",
     "grade": false,
     "grade_id": "cell-695e4689bc5509b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1\n",
    "Load the dataset and transform the data into Celsius (refer to documentation) then extract all of the rows which have minimum or maximum temperatures.\n",
    "\n",
    "__hint: when I did this step I had two DataFrame objects, each with ~80,000 entries in it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbfe393a2232a653ebbd81e518237a83",
     "grade": false,
     "grade_id": "cell-f508059dd84e9b7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Element</th>\n",
       "      <th>Data_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00094889</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00208972</td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00200032</td>\n",
       "      <td>2008-05-26</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00205563</td>\n",
       "      <td>2005-11-11</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00200230</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID        Date Element  Data_Value\n",
       "0  USW00094889  2014-11-12    TMAX          22\n",
       "1  USC00208972  2009-04-29    TMIN          56\n",
       "2  USC00200032  2008-05-26    TMAX         278\n",
       "3  USC00205563  2005-11-11    TMAX         139\n",
       "4  USC00200230  2014-02-27    TMAX        -106"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this code cell, transform the Data_Value column\n",
    "df[\"Data_Value\"] = df[\"Data_Value\"] / 10\n",
    "\n",
    "# Remove Leap Days\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.set_index(\"Date\")\n",
    "df = df[~((df.index.month == 2) & (df.index.day == 29))]\n",
    "df = df.reset_index()\n",
    "\n",
    "# Split into max and min\n",
    "max_df = df[df[\"Element\"] == \"TMAX\"]\n",
    "min_df = df[df[\"Element\"] == \"TMIN\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76f2478088402765c38ed2b9db771916",
     "grade": false,
     "grade_id": "cell-c5718635688cb408",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2\n",
    "In order to visualize the data we would plot the min and max data for each day of the year between the years 2005 and 2014 across all weather stations. But we also need to find out when the min or max temperature in 2015 falls below the min or rises above the max for the previous decade.\n",
    "\n",
    "If you did step 1 you have two Series objects with min and max times for the years 2005 through 2015. You can use Pandas `groupby` to create max and min temperature Series objects across all weather stations for each day of these years, and you can deal with the records for February 29 (the leap year) by dropping them.\n",
    "\n",
    "__hint: when I finished this step, I had two DataFrame objects, each with exactly 4015 observations in them__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame of maximum temperature by date\n",
    "max_temps = max_df.groupby(\"Date\")[\"Data_Value\"].max()\n",
    "# create a DataFrame of minimum temperatures by date\n",
    "min_temps = min_df.groupby(\"Date\")[\"Data_Value\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0edac9c92f1b79eb9b21f302a3259c5e",
     "grade": false,
     "grade_id": "cell-d3a1a2647a47fe31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 3\n",
    "Now that you have grouped the daily max and min temperatures for each day of the years 2005 through 2015, you can separate out the data for 2015. Then you can use the Pandas `groupby` function to find the max and min of the temperature data for each __day of the year__ for the 2005-2014 data.\n",
    "\n",
    "__hint: at the end of this step I had two DataFrames, one of maximum and the other of minimum values, which each had 365 observations in them. I also had another pair of similar DataFrames but only for the year 2015.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the minimum and maximum values for the day of the year for 2005 through 2014\n",
    "max_temps_2015 = max_temps[\"2015-01-01\":]\n",
    "max_temps_2005_2014 = max_temps[:\"2014-12-31\"]\n",
    "max_temps_2005_2014 = pd.DataFrame(\n",
    "    {\n",
    "        \"Data_value\": max_temps_2005_2014,\n",
    "        \"Day of Year\": pd.to_datetime(max_temps_2005_2014.index).day_of_year,\n",
    "    }\n",
    ")\n",
    "max_after_leap_day = (max_temps_2005_2014.index.month > 2) | (\n",
    "    (max_temps_2005_2014.index.month == 2) & (max_temps_2005_2014.index.day > 29)\n",
    ")\n",
    "max_temps_2005_2014.loc[max_after_leap_day, \"Day of Year\"] -= 1\n",
    "\n",
    "daily_max = max_temps_2005_2014.groupby(\"Day of Year\").max()\n",
    "\n",
    "\n",
    "# calculate the minimum and maximum values for the years 2015\n",
    "min_temps_2015 = min_temps[\"2015-01-01\":]\n",
    "min_temps_2005_2014 = min_temps[:\"2014-12-31\"]\n",
    "min_temps_2005_2014 = pd.DataFrame(\n",
    "    {\n",
    "        \"Data_value\": min_temps_2005_2014,\n",
    "        \"Day of Year\": pd.to_datetime(min_temps_2005_2014.index).day_of_year,\n",
    "    }\n",
    ")\n",
    "min_after_leap_day = (min_temps_2005_2014.index.month > 2) | (\n",
    "    (min_temps_2005_2014.index.month == 2) & (min_temps_2005_2014.index.day > 29)\n",
    ")\n",
    "min_temps_2005_2014.loc[min_after_leap_day, \"Day of Year\"] -= 1\n",
    "\n",
    "daily_min = min_temps_2005_2014.groupby(\"Day of Year\").min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7de066a05b833f7ded9353ee2215ba8",
     "grade": false,
     "grade_id": "cell-25711f5fdbe49515",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 4\n",
    "Now it's time to plot! You need to explore matplotlib in order to plot line graphs of the min and max temperatures for the years 2005 through 2014 and to scatter plot __only__ the daily 2015 temperatures that exceeded those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from calendar import month_abbr\n",
    "\n",
    "# put your plotting code here!"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mooc_adswpy_v1_assignment2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
