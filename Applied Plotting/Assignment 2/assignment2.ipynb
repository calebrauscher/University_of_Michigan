{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e45d05a7e6705e7bc18fff5d5890ef58",
     "grade": false,
     "grade_id": "cell-44ca835c70f3040a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": "IPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false; // disable scroll bar when displaying Folium map\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false; // disable scroll bar when displaying Folium map\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ae6111747a75bdb5c5393f44d1045577",
     "grade": false,
     "grade_id": "cell-c676d66924c74eea",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Assignment 2\n",
    "\n",
    "Before working on this assignment please read these instructions fully. In the submission area, you will notice that you can click the link to **Preview the Grading** for each step of the assignment. This is the criteria that will be used for peer grading. Please familiarize yourself with the criteria before beginning the assignment.\n",
    "\n",
    "The data for this assignment comes from a subset of The National Centers for Environmental Information (NCEI) [Global Historical Climatology Network daily (GHCNd)](https://www.ncei.noaa.gov/products/land-based-station/global-historical-climatology-network-daily) (GHCN-Daily). The GHCN-Daily is comprised of daily climate records from thousands of land surface stations across the globe - it's a wonderfully large dataset to play with! In particular, you will be asked to use data from the Ann Arbor Michigan location (my home!). and this is stored in the file: `assets/fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89.csv`\n",
    "\n",
    "Each row in this datafile corresponds to a single observation from a weather station, and has the following variables:\n",
    "* **id** : station identification code\n",
    "* **date** : date in YYYY-MM-DD format (e.g. 2012-01-24 = January 24, 2012)\n",
    "* **element** : indicator of element type\n",
    "    * TMAX : Maximum temperature (tenths of degrees C)\n",
    "    * TMIN : Minimum temperature (tenths of degrees C)\n",
    "* **value** : data value for element (tenths of degrees C)\n",
    "\n",
    "For this assignment, you must:\n",
    "\n",
    "1. Read the documentation and familiarize yourself with the dataset, then write a python notebook which plots line graphs of the record high and record low temperatures by day of the year over the period 2005-2014. The area between the record high and record low temperatures for each day should be shaded.\n",
    "2. Overlay a scatter of the 2015 data for any points (highs and lows) for which the ten year record (2005-2014) record high or record low was broken in 2015. (Based on the graph, do you think extreme weather is getting more frequent in 2015?)\n",
    "3. Watch out for leap days (i.e. February 29th), it is reasonable to remove these points from the dataset for the purpose of this visualization.\n",
    "4. Make the visual nice! Leverage principles from the first module in this course when developing your solution. Consider issues such as legends, labels, and chart junk.\n",
    "\n",
    "I've written some steps I think would be good to go through, but there are other ways to solve this assignment so feel free to explore the pandas library! What I really want to see is an image that looks like this sketch I drew at my desk:\n",
    "\n",
    "![](assets/chris_sketch.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8d9355fc55599cd2ad34fdd140baac1",
     "grade": false,
     "grade_id": "cell-f01cb0e8645e7c07",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap-glyphicons.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_49d6f1407ec007fcf9e537450262f01c {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 500.0px;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_49d6f1407ec007fcf9e537450262f01c&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_49d6f1407ec007fcf9e537450262f01c = L.map(\n",
       "                &quot;map_49d6f1407ec007fcf9e537450262f01c&quot;,\n",
       "                {\n",
       "                    center: [41.9164, -84.0158],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 9,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_a9d220302ec95ec9ae1e3ccfdae19bd1 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_a9d220302ec95ec9ae1e3ccfdae19bd1.addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_e1181dfc18a606dca6fad627da4a1fff = L.marker(\n",
       "                [41.9164, -84.0158],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_b003f4e13e39e4c2fc79e87879c6eacb = L.marker(\n",
       "                [42.2875, -83.7611],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_23814f6bcf6b3ec05ab71782fc1c9410 = L.marker(\n",
       "                [42.2417, -83.6933],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_eed66c902240f673ef04a1167b09ca32 = L.marker(\n",
       "                [42.2947, -83.7108],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_0a50baab389a2430cf5666ed5c7455ad = L.marker(\n",
       "                [41.84, -83.8608],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_17742b0e0e0b7c22358acc2a2088b164 = L.marker(\n",
       "                [42.0636, -83.4358],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_cd1180404f5ab0e854e0ce35ffe5988e = L.marker(\n",
       "                [42.3264, -84.0133],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_7706a4a592f3b00c4691410261997d6b = L.marker(\n",
       "                [41.9553, -83.6489],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_1a41a24e17d2401d6511ae5fa177963d = L.marker(\n",
       "                [42.4344, -83.9858],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_bca353f0723b7490164a1cf2223e4b28 = L.marker(\n",
       "                [42.1508, -84.0236],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_a3be60bd493e7fd14d4f17aaf9b2c735 = L.marker(\n",
       "                [42.0664, -83.6186],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_0df5edca808eb98f45ea36e4c477d218 = L.marker(\n",
       "                [42.0811, -83.6769],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_69fb20fb1c1fb915c1c631f8d094d847 = L.marker(\n",
       "                [41.9069, -83.4158],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_6d1318a471121bfb8f34cddc407987fc = L.marker(\n",
       "                [41.9497, -83.28],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_6c95441b34868f3b07b8422966eb9821 = L.marker(\n",
       "                [42.1611, -83.7819],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_eb8da637434b6d7e8026bb950127e6b0 = L.marker(\n",
       "                [42.1236, -83.82],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_2bf297cff1ce0d3c4797dab0d59eed03 = L.marker(\n",
       "                [41.8069, -83.5831],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_7e9982432417cf533b3df7355f81f9f7 = L.marker(\n",
       "                [42.0028, -83.9336],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_f21f5085fcad0e3cb289a9c6c985f24f = L.marker(\n",
       "                [42.0283, -84.1108],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_ef388df8ed4e5b2c44bbcc57313d39de = L.marker(\n",
       "                [42.4356, -83.7831],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_dfee7b6745823f1de9b2fc695e7fe65b = L.marker(\n",
       "                [41.5631, -83.4764],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_e875a2f865d9cf67f34d7d33daae0157 = L.marker(\n",
       "                [42.2667, -84.4667],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_c46119c0b85d28da9dbfd6831363c678 = L.marker(\n",
       "                [42.2333, -83.5333],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "    \n",
       "            var marker_ba6418dd40bf474ec1253f53ac2fa3a0 = L.marker(\n",
       "                [42.2228, -83.7444],\n",
       "                {}\n",
       "            ).addTo(map_49d6f1407ec007fcf9e537450262f01c);\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x20898b5f0a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#  I'll be using the folium package to render the data into a map in Jupyter.\n",
    "\n",
    "import folium\n",
    "import pandas as pd\n",
    "\n",
    "# get the location information for this dataset\n",
    "df = pd.read_csv(\"data/BinSize_d400.csv\")\n",
    "station_locations_by_hash = df[\n",
    "    df[\"hash\"] == \"fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89\"\n",
    "]\n",
    "\n",
    "# get longitude and lattitude to plot\n",
    "lons = station_locations_by_hash[\"LONGITUDE\"].tolist()\n",
    "lats = station_locations_by_hash[\"LATITUDE\"].tolist()\n",
    "\n",
    "# plot on a beautiful folium map\n",
    "my_map = folium.Map(location=[lats[0], lons[0]], height=500, zoom_start=9)\n",
    "for lat, lon in zip(lats, lons):\n",
    "    folium.Marker([lat, lon]).add_to(my_map)\n",
    "\n",
    "# render map in Jupyter\n",
    "display(my_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2ee9d3c5ac53844b3ed48aa157f6204",
     "grade": false,
     "grade_id": "cell-695e4689bc5509b6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 1\n",
    "Load the dataset and transform the data into Celsius (refer to documentation) then extract all of the rows which have minimum or maximum temperatures.\n",
    "\n",
    "__hint: when I did this step I had two DataFrame objects, each with ~80,000 entries in it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dbfe393a2232a653ebbd81e518237a83",
     "grade": false,
     "grade_id": "cell-f508059dd84e9b7c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Element</th>\n",
       "      <th>Data_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00094889</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00208972</td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00200032</td>\n",
       "      <td>2008-05-26</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00205563</td>\n",
       "      <td>2005-11-11</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00200230</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID        Date Element  Data_Value\n",
       "0  USW00094889  2014-11-12    TMAX          22\n",
       "1  USC00208972  2009-04-29    TMIN          56\n",
       "2  USC00200032  2008-05-26    TMAX         278\n",
       "3  USC00205563  2005-11-11    TMAX         139\n",
       "4  USC00200230  2014-02-27    TMAX        -106"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/fb441e62df2d58994928907a91895ec62c2c42e6cd075c2700843b89.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Element</th>\n",
       "      <th>Data_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00094889</td>\n",
       "      <td>2014-11-12</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USC00208972</td>\n",
       "      <td>2009-04-29</td>\n",
       "      <td>TMIN</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USC00200032</td>\n",
       "      <td>2008-05-26</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USC00205563</td>\n",
       "      <td>2005-11-11</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USC00200230</td>\n",
       "      <td>2014-02-27</td>\n",
       "      <td>TMAX</td>\n",
       "      <td>-10.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID       Date Element  Data_Value\n",
       "0  USW00094889 2014-11-12    TMAX         2.2\n",
       "1  USC00208972 2009-04-29    TMIN         5.6\n",
       "2  USC00200032 2008-05-26    TMAX        27.8\n",
       "3  USC00205563 2005-11-11    TMAX        13.9\n",
       "4  USC00200230 2014-02-27    TMAX       -10.6"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this code cell, transform the Data_Value column\n",
    "df[\"Data_Value\"] = df[\"Data_Value\"] / 10\n",
    "\n",
    "# Remove Leap Days\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df[\"day\"] = df.Date.dt.strftime(\"%m-%d\")\n",
    "df[df.day != \"02-29\"]\n",
    "df = df.drop(\"day\", axis=1)\n",
    "\n",
    "\n",
    "# Split into max and min\n",
    "max_df = df[df[\"Element\"] == \"TMAX\"]\n",
    "min_df = df[df[\"Element\"] == \"TMIN\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "76f2478088402765c38ed2b9db771916",
     "grade": false,
     "grade_id": "cell-c5718635688cb408",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 2\n",
    "In order to visualize the data we would plot the min and max data for each day of the year between the years 2005 and 2014 across all weather stations. But we also need to find out when the min or max temperature in 2015 falls below the min or rises above the max for the previous decade.\n",
    "\n",
    "If you did step 1 you have two Series objects with min and max times for the years 2005 through 2015. You can use Pandas `groupby` to create max and min temperature Series objects across all weather stations for each day of these years, and you can deal with the records for February 29 (the leap year) by dropping them.\n",
    "\n",
    "__hint: when I finished this step, I had two DataFrame objects, each with exactly 4015 observations in them__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DataFrame of maximum temperature by date\n",
    "max_temps = max_df.groupby(\"Date\")[\"Data_Value\"].max()\n",
    "# create a DataFrame of minimum temperatures by date\n",
    "min_temps = min_df.groupby(\"Date\")[\"Data_Value\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0edac9c92f1b79eb9b21f302a3259c5e",
     "grade": false,
     "grade_id": "cell-d3a1a2647a47fe31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 3\n",
    "Now that you have grouped the daily max and min temperatures for each day of the years 2005 through 2015, you can separate out the data for 2015. Then you can use the Pandas `groupby` function to find the max and min of the temperature data for each __day of the year__ for the 2005-2014 data.\n",
    "\n",
    "__hint: at the end of this step I had two DataFrames, one of maximum and the other of minimum values, which each had 365 observations in them. I also had another pair of similar DataFrames but only for the year 2015.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the minimum and maximum values for the day of the year for 2005 through 2014\n",
    "\n",
    "# calculate the minimum and maximum values for the years 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7de066a05b833f7ded9353ee2215ba8",
     "grade": false,
     "grade_id": "cell-25711f5fdbe49515",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Step 4\n",
    "Now it's time to plot! You need to explore matplotlib in order to plot line graphs of the min and max temperatures for the years 2005 through 2014 and to scatter plot __only__ the daily 2015 temperatures that exceeded those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from calendar import month_abbr\n",
    "\n",
    "# put your plotting code here!"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mooc_adswpy_v1_assignment2"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
